# 8장 '정확히 한 번' 의미 구조

* 카프카의 정확히 한 번 의미 구조는 두 개의 핵심 기능의 조합으로 이뤄진다.
  * 명득성 프로듀서는 프로듀서 재시도로 인해 발생하는 중복을 방지한다.
  * 트랜잭션 의미 구조는 스트림 처리 애플리케이션에서 정확히 한 번 처리를 보장한다.

## 8.1 멱등성 프로듀서

* 여러 번 실행해도 한 번 실행한 것과 결과가 같은 서비스를 '멱등적' 이라고 한다.

### 8.1.1 멱등적 프로듀서의 작동 원리

* 멱등적 프로듀서 기능을 켜면 모든 메시지는 고유한 프로듀서 ID와 시퀀스 넘버를 가진다.
* 두 값을 합치면 각 메시지의 고유한 식별자를 가지게 되며, 해당 값을 통해 각 파티션에 쓰여진 마지막 5개 메시지들을 추적한다.
* 브로커가 중복 메시지를 수신하게되면 적절한 에러를 발생시켜 중복 메시지를 거부한다.

#### 1. 프로듀서 재시작

* 프로듀서가 재시작될 때 멱등적 프로듀서 기능이 활성화되어 있는 경우, 프로듀서는 초기화 과정에서 카프카 브로커로부터 프로듀서 ID를 생성 받는다.
* 트랜잭션 기능이 켜지지 않았다면, 매번 새로운 프로듀서 ID가 생성된다.
* 앞선 경우에 메시지가 중복 전송되면, 브로커는 이를 인지하지 못한다.
  * 새로운 프로듀서 ID에 새로운 시퀀스 넘버의 조합이기 때문이다.

#### 2. 브로커 장애

* 파티션에 대한 리더와 레플리카 모두 메모리에 최근 5개의 메시지를 추적하고 있기 때문에 새 리더가 선출되더라도 메시지 중복을 감지할 수 있다.
* 기존 리더가 복구되어 다시 리더가 되더라도, 현재 리더로부터 동기화를 진행하고 리더가 되기 때문에 메시지 중복을 감지할 수 있다.

### 8.1.2 멱등적 프로듀서의 한계

* 카프카 먹등적 프로듀서는 프로듀서의 내부 로직으로 인한 재시도가 발생할 경우 생기는 중복만 방지한다.
* 동일한 메시지를 가지고 ``producer.send()```를 두 번 호출하면 명등적 프로듀서가 개입하지 않아 중복 메시지가 생기게 된다.

### 8.1.3 멱등적 프로듀서 사용법

* 프로듀서 설정에 enable.idempotence=true 설정을 하면 된다.
* 명등적 프로듀서 설정을 하면 다음과 같은 것들이 변경된다.
  * 프로듀서 ID를 받아오기 위해 프로듀서 시동 과정에서 API를 하나 더 호출한다.
  * 전송되는 각각의 레코드 배치에는 프로듀서 ID와 배치 내 첫 메시지의 시퀀스 넘버가 포함된다.
  * 브로커들은 모든 프로듀서 인스턴스에서 들어온 레코드 배치의 시퀀스 넘버를 검증해서 메시지 중복을 방지한다.
  * 장애가 발생하더라도 각 파티션에 쓰여지는 메시지들의 순서는 보장된다.


## 8.2 트랜잭션

* 트랜잭션 기능은 카프카 스트림즈를 사용해서 개발된 애플리케이션에 정확성을 보장하기 위해 도입되었다.
* 카프카의 트랜잭션은 스트림 처리 애플리케이션을 위해 개발되었기 때문에 스트림 처리 애플리케이션의 기본 패턴인 '읽기-처리-쓰기'패턴에서 사용되도록 개발되었다.

### 8.2.2 트랜잭션이 해결하는 문제

#### 1. 애플리케이션 크래시로 인한 재처리

* 애플리케이션이 메시지를 읽어온 후 다른 토픽에 메시지를 쓰고난 뒤, 오프셋을 커밋하기 전에 종료되면, 새로운 컨슈머 리밸런스로 메시지가 중복 소비될 수 있다.

#### 2. 좀비 애플리케이션에 의해 발생하는 재처리

* 좀비 애플리케이션이 발생하여, 기존에 조회한 데이터에 대한 처리를 진행할 수 있다. 즉, 이미 다른 컨슈머에서 데이터를 다시 조회하여 처리했지만, 좀비 애플리케이션 또한 데이터를 처리할 수 있다.

### 8.2.3 트랜잭션은 어떻게 '정확히 한 번'을 보장하는가?

* 카프카에서 트랜잭션은 다수 파티션 쓰기 기능을 도입했다.
  * 다수 파티션 쓰기 기능은 오프셋을 커밋하는 것과 결과를 쓰는 것은 둘 다 파티션에 메시지를 쓰는 과정을 수반한다는 점에 착안한 것이다.
* 트랜잭션을 사용해서 원자적 다수 파티션 쓰기를 수행하려면 **트랜잭션적 프로듀서**를 사용해야 한다.
  * transactional.id를 관리하며 동일한 프로듀서를 식별하기 위해 사용한다.
  * 재시작한뒤에도 transactional.id는 유지된다.
* 애플리케이션의 좀비 인스턴스가 중복 프로듀서를 생성하는 것을 방지하려면 좀비 펜싱 또는 애플리케이션의 좀비 인스턴스가 출력 스트림에 결과를 쓰는 겻을 방지해야한다.
  * transactional.id에 해당하는 에포크를 값을 관리하여 같은 transactional.id에 대해 낮은 에포크 값은 메시지 전송을 무시한다.
* 트랜잭션 기능을 활용하여 쓰여진 레코드들은 트랜잭션이 실패되더라도 토픽에 쓰여진다.
  * isolation.level이 read_committed로 잡혀있는 경우 커밋된 트랜잭션에 속한 메시지나, 트랜잭션에 포함되지 않았던 메시지를 조회한다.
  * isolation.level이 read_uncommitted로 잡혀있는 경우 모든 레코드들이 조회된다.
* 메시지의 읽기 순서를 보장하기 위해 read_committed 모드에서는 아직 진행중인 트랜잭션이 처음으로 시작된 시점(LSO) 이후에 쓰여진 메시지는 리턴하지 않는다.

### 8.2.4 트랜잭션으로 해결할 수 없는 문제들

#### 1 스트림 처리에 있어서의 부수 효과

* 카프카 트랜잭션은 레코드를 쓰는 것에만 해당한다. 따라서 외부 api 호출에 대해 '정확히 한 번'을 보장하지 않는다.

#### 2. 카프카 토픽에서 읽어서 데이터베이스에 쓰는 경우

* 다른 두 플랫폼에 대한 트랜잭션이기때문에 앞선 부수 효과와 마찬가지로 보장할 수 없다.

#### 3. 데이터베이스에서 읽어서, 카프카에 쓰고, 여기서 다시 다른 데이터베이스에 쓰는 경우

* 카프카는 종단 보장에 필요한 기능을 제공하지 않는다.
* 카프카 트랜잭션은 커밋되지 않는 레코드를 볼 수 없는 건 사실이지만, 일부 토픽에서 랙이 발생해 커밋된 트랜잭션의 레코드를 봤을 거라는 보장 또한 없기에 트랜잭션의 경계를 알 수 없다.

#### 4. 한 클러스터에서 다른 클러스터로 데이터 복제

* 하나의 카프카 클러스터에서 다른 클러스터로 데이터 복사는 '정확히 한 번'을 보장할 수 있다. 하지만 이는 트랜잭션의 원자성을 보장하지 않는다.
  * 즉, 토픽의 일부만 구독한 경우 전체 트랜잭션의 일부만 복사할 수 있기 때문이다.

#### 5. 발행/구독 패턴

* 발행/구독 패턴은 '정확히 한 번'을 보장하지 않는다. 만약에 컨슈머가 read_committed 설정이 되어 있지 않다면, 커밋되지 않은 메시지를 조회할 수 있다.

### 8.2.6 트랜잭션 ID와 펜싱

* 카프카 2.5까지는 펜싱을 보장하는 유일한 방법은 트랜잭션 ID를 파티션에 정적으로 대응시켜 보는 것뿐이었다.
* 이후 버전에서 트랜잭션 ID와 컨슈머 그룹 메타데이터를 함께 사용하는 펜싱을 도입했다.
  * 컨슈머 그룹 내의 특정 컨슈머가 종료되더라도, 다른 컨슈머가 같은 컨슈머 그룹에 속해만 있다면 종료된 컨슈머의 역할을 대신할 수 있는 것이다.

### 8.2.7 트랜잭션의 작동 원리

* 카프카 트랜잭션 기능의 기본적인 알고리즘은 찬디-램포트 스냅샷 알고리즘의 영향을 받았다.
  * 통신 채널을 통해 '마커'라 불리는 컨트롤 메시지를 보내고, 이 마커의 도착을 기준으로 일관적인 상태를 결정한다.
  * 카프카 트랜잭션은 마커를 통해 트랜잭션의 상태를 추적한다.
  * 트랜잭션에 대해 커밋 요청을 보내면 트랜잭션 코디네이터는 트랜잭션에 관련된 모든 파티션에 커밋 마커를 쓴다.
  * 커밋을 쓰는 과정에서 2단계 커밋과 트랜잭션 로그를 통해 일관성을 유지한다.
    1. 현재 진행중인 트랜잭션이 존재함을 로그에 기록한다. 연관된 파티션들 역시 함께 기록한다.
    2. 로그에 커밋 혹은 중단 시도를 기록한다.
    3. 모든 파티션에 트랜잭션 마커를 쓴다.
    4. 트랜잭션이 종료됨을 로그에 쓴다.
* 카프카는 트랜잭션 로그를 __transaction_state 토픽에 저장한다.
* 카프카는 트랜잭션을 처리하던 중 코디네이터가 중단되면, 새로운 코디네이터가 해당 로그들을 조회하여 트랜잭션 처리를 다시 시작한다.