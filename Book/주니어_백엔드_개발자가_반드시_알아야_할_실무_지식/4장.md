## 우리는 문제가 없는데
은행 A의 새로운 서비스를 배포했지만, 가입 과정에서 사용한 외부 서비스가 마비됨에 따라 은행 A의 서비스에 장애가 발생했음


## 타임아웃
특정 api에서 외부 서비스의 api를 활용한다면, 외부 서비스에서 지연이 발생할 때를 고려해야합니다. 예를들어 설명해보겠습니다.

- 서비스 A는 200개의 요청을 동시에 받을 수 있다.
- 서비스 A는 외부 서비스 B를 호출한다.
- 외부 서비스 B는 현재 지연이 발생하여 응답에 60초가 소요된다.

위 상황에서 서비스 A로 200개의 요청이 전송되고 10초 뒤 100개의 요청이 전송된다면, 뒤의 100개의 요청에 대해서 사용자들이 불편을 겪을 수 있습니다.

추가로, 뒤 100개의 요청을 보낸 사용자들이 기다리지 않고 새로고침을 통해 추가적인 요청을 보내개된다면 서버의 응답이 더 느려지게 됩니다. 

만일 이런 상황에서 서비스 A가 외부 서비스 B를 호출할 때, 타임아웃 5초를 설정하였다면, 초기 200개의 요청은 100개의 요청이 더 들어오기 전에 타임아웃 응답을 반환하며, 이후 요청에 대해서 정상적으로 응답할 수 있게 되었을 겁니다.

### 2가지 타임아웃: 연결 타임아웃, 읽기 타임아웃
API 통신 과정에 대해서 간단하게 표현하면, "외부 서비스와의 연결 -> 요청 정보 전송 -> 연결 종료"로 표현할 수 있습니다.


위 과정에서 개발자가 타임아웃을 설정할 수 있는 구간이 2개가 있습니다.

1. 외부 서비스와 연결 시도에서 설정하는  **연결 타임아웃(Connection Timeout)** . 일반적으로 3~5초로 설정합니다.
2. 외부 서비스와 연결이 성공한 뒤 요청을 보내고 이에 대한 응답이 돌아올 때 설정하는 **읽기 타임아웃(Read Timeout)** . 일반적으로 5~30초로 설정합니다.

읽기 타임아웃의 경우 외부 연동 서비스의 특징에 따라 처리 시간이 달라질 수 있기에 (ex PG) 연동 서비스 특징에 따라 적절히 설정하는게 중요합니다.


### 쓰기 타임아웃
타임아웃에는 연결 타임아웃, 읽기 타임아웃뿐만 아니라 **쓰기 타임아웃(Write Timeout)** 이 존재합니다. 이는 POST와 같이 클라이언트에서 서버로 데이터를 전송할 때 설정하는 타임아웃입니다.
좀 더 자세히 예기해보자면 다음과 같은 상황에서 발생할 수 있습니다.

1. 대상 서버 애플리케이션이 데이터를 읽기 못해 수신 버퍼가 가득 참
2. 서버가 클라이언트로 윈도우 사이즈를 0으로 전송함
3. 클라이언트는 더 이상 데이터를 서버로 전송하지 않음
4. 서버가 회복되지 않고 쓰기가 더 이상 진행되지 않으면 쓰기 타임아웃 발생

그 외의 대역폭 문제로 인해 쓰기 타임아웃이 발생할 수 있지만, 현대의 인터넷 대역폭은 무제한에 가깝기 때문에 해당 사항에 대해서는 정리하지 않겠습니다.


### Spring RestClient, WebClient에서 타임아웃 설정하기
#### RestClient
```java
@Configuration
public class RestClientConfig {
    
    @Bean
    public RestClient restClient() {
        return RestClient.builder()
            .requestFactory(httpRequestFactory())
            .build();
    }
    
    @Bean
    public ClientHttpRequestFactory httpRequestFactory() {
        HttpComponentsClientHttpRequestFactory factory = 
            new HttpComponentsClientHttpRequestFactory();
        
        // 연결 타임아웃: 5초
        factory.setConnectTimeout(Duration.ofSeconds(5));
        
        // 읽기 타임아웃: 30초
        factory.setReadTimeout(Duration.ofSeconds(30));
        
        return factory;
    }
}
```
#### WebClient
```java
@Configuration
public class WebClientConfig {
    
    @Bean
    public WebClient webClient() {
        HttpClient httpClient = 
	        HttpClient.create()
	            .option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 5000)  
	            // 연결 타임아웃: 5초
		        .responseTimeout(Duration.ofSeconds(30));            
		        // 읽기 타임아웃: 30초
        
        return WebClient.builder()
            .clientConnector(new ReactorClientHttpConnector(httpClient))
            .build();
    }
}
```


## 재시도
외부 연동에 실패했을 때, 처리 방법 중 하나로 재시도하는 것이 있습니다.

### 재시도 가능 조건
외부 서비스 연동시 API 호출이 실패할 때, 무조건 재시도하면 안됩니다. 재시도할 때에는 대상 API가 **단순 조회 또는 멱등한 기능**이라면 재시도해도 괜찮습니다.

### 재시도 횟수와 간격
재시도할 때에는 **횟수**와 **간격**에 대해서 결정해야 합니다.
재시도 횟수의 경우 일반적으로 1~2회가 적당합니다. 간격의 경우에는 다음과 같은 전략들이 있습니다.

#### 1. 고정 지연(Fixed Delay)

매전 동일한 간격으로 재시도합니다. 구현은 간단하지만, 네트워크 혼잡시 더 네트워크에 부하를 줄 수 있습니다.

```kotlin
fun connectWithFixedDelay(host: String, port: Int, maxRetries: Int = 3, delay: Int = 1){
	repeat(maxRetries){
		try{
			// 커넥션 연결
		} catch(timeoutException: SocketTimeoutException){
			Thread.sleap(delay * 1000)
		}
	}
}
```

####  2. 지수 백오프(Exponential Backoff)

재시도할 때마다 대기 시간이 지수적으로 증가합니다. 네트워크 혼잡을 완화하는데 효과적입니다.

```kotlin
fun connectWithExponentialBackoff(host: String, port: Int, maxRetries: Int = 3, delay: Int = 1){
	repeat(maxRetries){ attempt ->
		try{
			// 커넥션 연결
		} catch(timeoutException: SocketTimeoutException){
			val baseDelay = delay * 2.pow(attempt)
			Thread.sleep(baseDelay)
		}
	}
}
```

#### 3. 지터 포함 지수 백오프(Exponential Backoff)

지수 백오프에 랜덤요소를 추가합니다. 동시에 많은 클라이언트가 재시도 요청할 때, 시스템적 랜덤을 통해 충돌을 방지합니다. 이를 통해 네트워크 혼잡을 줄일 수 있습니다.

>  The time series above makes a great case for jitter – we want to spread out the spikes to an approximately constant rate
>  https://aws.amazon.com/ko/blogs/architecture/exponential-backoff-and-jitter/


```kotlin
fun connectWithExponentialBackoffAndJitter(host: String, port: Int, maxRetries: Int = 3, delay: Int = 1){
	repeat(maxRetries){ attempt ->
		try{
			// 커넥션 연결
		} catch(timeoutException: SocketTimeoutException){
			val baseDelay = delay * 2.pow(attempt)
			
			val jitterFactor = 0.1
			val jitterRange = baseDelay * jitterFactor
			val jitter = Random.nextLong(-jitterRange, jitterRange+1)
			
			
			Thread.sleep(baseDelay)
		}
	}
}
```


#### 4. 선형 백오프(Linear Backoff)

일정한 비율로 대기 시간이 증가합니다. 지수 백오프보다 빠른 재시도가 가능하지만, 네트워크 부하가 있을 수 있습니다.

```kotlin
fun connectWithExponentialBackoff(host: String, port: Int, maxRetries: Int = 3, delay: Int = 1){
	repeat(maxRetries){ attempt ->
		try{
			// 커넥션 연결
		} catch(timeoutException: SocketTimeoutException){
			val baseDelay = delay * (attempt + 1)
			Thread.sleep(baseDelay)
		}
	}
}
```


## 동시 요청 제한

연동 서비스가 동시에 처리할 수 있는 수준보다 더 많은 요청이 들어온다면, 요청 가능한 수만큼만 연동 서비스로 요청을 보내고, 나머지 요청을 503 Service Unavailable로 반환하는게 좋습니다.

### 벌크헤드 패턴

벌크헤드 패턴은 분산 시스템과 마이크로서비스 아키텍처에서 장애 격리를 위해 사용되는 디자인 패턴이며, 단일 애플리케이션 내부에서 리소스를 격리하여 한 부분의 장애가 전체 시스템에 전파되는 것을 방지합니다.

방지하는 방법으로는 다음과 같습니다.

1. 스레드 풀 격리
```kotlin
// 서로 다른 서비스를 위한 별도 스레드 풀 
val userServicePool = ThreadPoolExecutor(10, 20, ...);
val paymentServicePool = ThreadPoolExecutor(5, 10, ...);
val notificationServicePool = ThreadPoolExecutor(3, 8, ...);
```
2. 연결 풀 격리
```kotlin
val userClient = RestClient()...
val paymentClient = RestClient()...
val notificationClient = RestClient()...
```
3. 메모리 격리
   - 캐시 메모리 할당량 제한으로, 각 서비스에 따라 독립적인 캐시를 활용합니다.

## 서킷 브레이커
서킷 브레이커는 외부 연동 서비스에 장애가 발생하여 응답이 길어질 때, 빠르게 실패하여 사용자들로 하여금 대기하지 않고 빠르게 에러를 보여줄 수 있도록 해줍니다. 즉, 차단기로 생각하면 됩니다.

서킷 브레이커는 **닫힘, 열림, 반 열림** 이렇게 3개의 상태를 가집니다.
서킷 브레이커는 닫힘 상태에서 시작합니다. 이후 연동 서비스에서 장애가 임계치 이상 발생하게 되면 열림 상태로 전환됩니다. 이때부터는 연동 서비스로 요청이 가지 않고, 바로 에러를 반환합니다. 이후 일정 시간이 지나면 반 열림 상태로 전환되고, 요청 중 일부만 연동 서비스로 요청을 보냅니다. 이 때 일부 전송된 요청들이 정상적으로 응답을하면 최종적으로 닫힘 상태로 전환됩니다.

실무에서는 gateway 설정을 사용한다네요.

## 외부 연동과 DB 연동

외부 연동 api를 매인 비즈니스 로직에서 호출할 때, 외부 api가 post와 같이 상태를 변경해야한다면 트랜잭션 관리를 잘해야합니다.
예를들면 주문로직에 외부 서비스의 포인트를 차감하는 api를 호출해야한다면, 외부 상태와 내부 주문로직간 일관성을 유지해야 합니다.

또한 외부 연동 api로 인해 전체 트랜잭션이 길어지는 문제가 발생할 수 있습니다.

상태관리가 잘되어야하고 트랜잭션의 단위를 짧게 가져가기 위해 이벤트 + 사가 패턴을 사용하는게 좋을 것 같습니다.


## HTTP 커넥션 풀

HTTP 커넥션 수립에도 시간이 상당히 소요되기 때문에 커넥션 풀을 통해 커넥션을 관리하는 것이 좋습니다.
커넥션 풀을 사용할 때 고려해야할 점이 있습니다.
- HTTP 커넥션 풀 크기
- 풀에서 HTTP 커넥션을 가져올 떄까지 대기하는 시간
- HTTP 커넥션을 유지할 시간

추가로, 커넥션 풀의 크기를 연동 서비스의 성능을 고려하지 않고 정하게되면 연동 과정에서 서비스에 장애가 발생할 수 있습니다.


## 연동 서비스 이중화

서비스가 성장함에 따라 연동 서비스의 이중화를 고려해야합니다. 당근