# 1장 사용자 수에 따른 규모 확장성

## 단일 서버

서비스가 크지 않고 단일 서버 내에서 데이터베이스, 웹 애플리케이션이 동시에 실행될 수 있다.

여기서 집고 넘어가야할 부분은 DNS 처리 부분에 관한 것이다.

1. 클라이언트 사이드: DNS 질의를 하기 전에 클라이언트 내부에 캐싱된 정보를 확인합니다.
    * 브라우저 캐시 확인
    * OS 캐시 및 hosts 파일 확인
2. 로컬 DNS 서버 (Recursive Resovler) 질의: 클라이언트에서 확인할 수 없을 때, 클라이언트에 설정된 로컬 DNS 서버에 질의를 보냄
3. 루트 네임서버 (Root Name Server) 질의: DNS 계층 최상위인 루트 노드에 질의함
4. TLD 네임서 (Top-Level Domain Server) 질의: 로컬 DNS는 루트 서버가 알려준 도메인(ex: .com) TLD 서버로 이동해 재질의 함
5. Authoritative 네임서버 질의: 로컬 DNS는 마지막으로 실제 도메인 관리를 맡고 있는 Authoritative 네임서버에 질의

가비아에서 도메인을 구입하고 AWS Route 53에 해당 도메인을 등록한 후, Route 53이 제공한 NS(Name Server) 레코드 값을 가비아 설정 페이지에 입력하면, 실질적인 Authoritative 네임서버의 역할은 AWS Route 53이 수행하게 됨. 이때 가비아는 도메인 등록 대행자(Registrar)로서, 상위 TLD 네임서버(.com 등)에 '이 도메인의 관리자는 AWS Route 53입니다'라는 정보를 등록해 주는 역할을 수행

## 데이터베이스

서비스 사용자가 늘어나면 단일 서버만으로는 모든 요청을 처리하기 어려워지므로, 자연스럽게 여러 대의 서버를 운영하는 구조로 확장하게 됩니다.

이때 여러 애플리케이션 서버가 하나의 데이터를 일관성 있게 공유해야 하므로, 더 이상 각 서버 내부에 데이터베이스를 둘 수 없게 됩니다. 따라서 데이터베이스를 별도의 전용 서버로 분리하여 중앙에서 관리하는 구조로 전환하게 됩니다.

## 수직적 규모 확장 VS 수평적 규모 확장

**수직적 확장(Scale-up)**은 CPU나 RAM과 같은 하드웨어를 업그레이드하여 '단일 서버의 성능' 자체를 높이는 방식이다. 반면 **수평적 확장(Scale-out)**은 서버의 대수를 늘려 처리 부하를 여러 대에 분산시킴으로써 전체 성능을 향상시키는 전략.

수직적 확장은 하드웨어 업그레이드에 물리적·비용적 한계가 존재하므로, 트래픽이 급증하는 대규모 서비스에서는 유연한 확장이 가능한 수평적 확장을 주로 채택

### 로드밸런서

로드밸런서는 부하 분산 집합(Load Balancing Set) 내 다수의 웹 서버에 트래픽을 고르게 배분하는 역할을 수행.

또한, 외부에는 Public IP만 노출하고 내부 서버는 Private IP를 유지함으로써, 외부 네트워크와의 안전한 통신을 중계 및 보안 강화.

### 데이터베이스 다중화

데이터베이스를 읽기(Read)와 쓰기(Write)로 분리 구성하여 성능 및 가용성 극대화 가능.

이를 통해 읽기 요청 부하를 효율적으로 분산하고, 쓰기(Master) 서버 장애 시에도 읽기 서비스의 지속적인 운영을 보장하여 시스템 안정성 확보.

단, 복제 지연(Replication Lag) 고려 및 장애 발생 시 읽기 전용 서버(Slave)를 쓰기 서버로 승격(Failover)하는 복구 프로세스 수립 필요.

특히, AWS Multi-AZ(Availability Zone) 배포 환경에서는 고가용성을 위해 동기식 복제(Synchronous Replication) 방식을 채택.
이는 일반적인 DB 엔진 레벨의 비동기식 Binary Log 복제가 아닌, 인프라 레벨에서 Write 시스템 콜 발생 시 로컬 스토리지와 원격 AZ 스토리지에 동시에 데이터를 기록하는 블록 레벨 복제(Block-Level Replication) 메커니즘을 통해 데이터 정합성(Consistency)을 강력하게 보장함.

아울러 멀티 마스터(Multi-Master) 구조를 도입하고자 한다면, AWS Aurora와 같이 단일 공유 스토리지(Shared Storage) 기반의 아키텍처를 활용하거나, 애플리케이션 레벨에서 Cluster Aware 기능을 구현하여 데이터 충돌 및 정합성 문제를 해결해야 함

## 캐시

일반적으로 읽기(Read) 요청이 쓰기(Write)보다 빈번하게 발생하므로, 캐싱(Caching)을 도입하여 데이터베이스 부하를 획기적으로 절감 가능.

단, 캐시 데이터의 생명 주기(TTL; Time To Live) 설정을 통해 데이터의 신선도와 메모리 효율성 간의 최적화된 균형점을 찾아야 함.

또한, 단일 캐시 노드 장애 시 서비스 전체에 미치는 영향(SPOF)을 방지하기 위해 캐시 클러스터링(Clustering) 또는 이중화(Replication) 구성을 고려해야 하며,
메모리 부족 시 데이터를 효율적으로 관리하기 위한 방출 정책(Eviction Policy)으로 LRU(최근 사용 이력), LFU(사용 빈도), FIFO(선입선출) 등 서비스 특성에 맞는 알고리즘을 선정 및 적용해야 함.

특히 멀티 리전 환경에서는, 지연(latency)과 일관성(consistency) 사이의 트레이드오프에 따라 로컬 캐시(Local Cache)와 글로벌 캐시(Global Cache) 전략을 병행하거나 선택적으로 적용.

* 글로벌 캐시는 여러 리전에 걸쳐 데이터의 일관성을 보장하지만, 네트워크 지연이 수반됨.
* 로컬 캐시는 각 리전별로 빠른 캐싱 성능을 제공하나, 데이터 싱크(동기화) 이슈 발생 가능.

워크로드 특성과 서비스 요구사항에 따라 로컬 캐싱과 글로벌 캐싱의 혼합 전략 또는 분리 운영 전략 수립 필요.

## 콘텐츠 전송 네트워크(CDN)

일반적으로 CDN은 전 세계에 분산된 엣지 노드(Edge Node)를 통해 정적 컨텐츠(이미지, 동영상, JS/CSS 등)를 사용자와 가까운 위치에서 빠르게 전달함으로써 응답 속도 향상 및 원본 서버의 트래픽 부하 절감 가능.

단, 캐시 데이터의 동기화 정책(TTL 설정, Purge 전략 등)을 통해 컨텐츠의 신선도와 전송 효율 사이의 최적화된 균형점 설계 필요.

또한, CDN Provider 장애 시 서비스 전체가 멈출 수 있는 단일 장애지점(SPOF; Single Point of Failure) 문제가 발생할 수 있으므로, Multi-CDN(복수 CDN 공급자 동시 운영) 및 DNS 기반 자동 우회(Failover), 애플리케이션 레벨 백업 경로 설계 등 이중화(Business Continuity) 아키텍처 반영 필요.

멀티 리전 환경에서는 지역별 Edge Node의 분포, 국제망 지연(Latency), 규제/검열 이슈까지 고려하여 CDN PoP 구성 및 관리 전략을 병행·적용.

하나의 CDN을 사용할 경우, 장애 발생 시 빠른 대체 경로(Backup Origin, CDN Failover) 구현 필요.

복수 CDN을 사용할 경우, 실시간 성능 모니터링 기반 동적 트래픽 분산(DNS Weight/Anycast) 및 캐시 정책 일관성(Security, Invalidation 등) 유지 전략 수립 필요.

서비스 요구사항에 따라 단일/복수 CDN 운용 방식, 장애 대응 아키텍처, 캐시 일관성 및 동기화 전략을 선택적으로 설계.

## 무상태(stateless) 웹 계층

일반적으로 세션 데이터 저장 방식은 다음과 같이 분류함.

1. 메모리 기반 저장소(In-Memory Store)
* Redis, Memcached 등 인메모리 캐시 시스템에 세션 데이터 저장
* 서버 간 분산 처리 또는 클러스터링을 통해 공유 세션 구현 가능

2. 파일 기반 저장(File-based)
* 서버의 로컬 파일 시스템에 세션 데이터 직접 저장
* 단일 서버 환경 및 소규모 서비스에 적합

3. 데이터베이스 기반 저장(Database-backed)
* RDBMS(MySQL, PostgreSQL 등) 또는 NoSQL(MongoDB 등)에 세션 저장
* 영속성 및 서버 확장성 확보, 대규모 서비스에 활용

4. 클라이언트 측 저장(Client-side Storage)
* 쿠키, LocalStorage, SessionStorage 등 브라우저에 데이터 저장
* 서버 부하 감소, 민감 정보 처리 시 보안 고려 필요

## 데이터 센터

멀티 리전 서비스 운영 시, 사용자의 위치(지리적 근접성)에 따라 가장 가까운 데이터센터로 트래픽을 라우팅하는 지리적 라우팅(Geo Routing) 전략 적용.

이때, 여러 데이터센터 간 데이터베이스 동기화(Replication 및 Consistency) 메커니즘 설계가 서비스 일관성 및 무중단 운영을 위해 핵심적 요소임.

## 메시지 큐

메시지 큐(Message Queue)를 활용하여 부수적인 작업 또는 고부하 워크로드 처리를 별도의 비동기 프로세스로 분리 가능

## 데이터베이스의 규모 확장

일반적으로 데이터베이스 규모 확장 방식은 **수직적 확장(Scale-Up)**과 **수평적 확장(Scale-Out)**으로 구분.

수직적 확장(Scale-Up)
* 단일 데이터베이스 서버의 CPU, 메모리, 스토리지 등 하드웨어 업그레이드를 통해 처리 성능 극대화.
* 구조가 단순하고 관리가 용이하나, 확장성/가용성 물리적 한계 및 단일 장애점(SPOF) 발생 가능.

수평적 확장(Scale-Out)
* 여러 데이터베이스 서버(샤드)에 데이터를 분산 저장하여 트래픽 및 용량 분산 처리.
* 확장성, 내결함성, 장애 복구력 모두 향상 가능.
* 샤딩(Sharding) 적용 시, 서버 추가/조정에 따라 일부 혹은 전체 데이터 이동 현상 발생.
* 데이터 조인에 어려움이 있음

Consistent Hashing(해시링)
* 키(hash)를 원형 링에 할당하고 각 서버 노드는 링 상의 특정 위치(구간) 담당.
* 서버의 추가/삭제 시 전체가 아닌 해당 구간 데이터만 이동하므로, 데이터 이동량 최소화 및 분산 균형도 향상.

가상 노드(Virtual Node)
* 물리적 서버 한 대를 해시링 상 여러 가상 노드로 매핑하여 데이터 분포 불균형 완화.
* 서버 조정 시 각 가상 노드에 해당하는 데이터만 제한적으로 이동하여 시스템의 확장 및 데이터 균형성 극대화.

